---
title: "fastLink: Fast Probabilistic Record Linkage"
output: 
  md_document:
    variant: markdown_github
---
# fastLink: Fast Probabilistic Record Linkage [![Build Status](https://travis-ci.com/kosukeimai/fastLink.svg?token=JxpGcfuMTdnnLSenfvSD&branch=master)](https://travis-ci.com/kosukeimai/fastLink)

## Installation Instructions
As `fastLink` is hosted on a private Github repo, you will need a
Github personal access token (PAT) to install using
`devtools`. Instructions for setting up your own PAT can be found at
<https://github.com/settings/tokens>.

Once you have a PAT, `fastLink` can be installed from the private repo using `devtools` as
follows:
```{r eval = FALSE}
library(devtools)
install_github("kosukeimai/fastLink", auth_token = "[YOUR PAT HERE]")
```

## Simple usage example
The linkage algorithm can be run either using the `fastLink()`
wrapper, which runs the algorithm from start to finish, or
step-by-step. We will outline the workflow from start to finish
using both examples. In both examples, we have two dataframes
called `dfA` and `dfB` that we want to merge together, and they
have seven commonly named fields:

- `firstname`

- `middlename`

- `lastname`

- `housenum`

- `streetname`

- `city`

- `birthyear`

### Running the algorithm using the `fastLink()` wrapper
The `fastLink` wrapper runs the entire algorithm from start to finish, as seen below:
```{r eval = TRUE, echo = TRUE, tidy=FALSE, warning=FALSE, error=FALSE, message=FALSE}
## Load the package and data
library(fastLink)
data(samplematch)

matches.out <- fastLink(
  dfA = dfA, dfB = dfB, 
  varnames = c("firstname", "middlename", "lastname", "housenum", "streetname", "city", "birthyear"),
  stringdist.match = c(TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, FALSE),
  partial.match = c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE)
)
```

- `varnames` should be a vector of variable names to be used for
matching. These variable names should exist in both `dfA` and `dfB`

- `stringdist.match` should be a vector of booleans of the same length
  as `varnames`. `TRUE` means that string-distance matching using the
  Jaro-Winkler similarity will be used.

- `partial.match` is another vector of booleans of the same length as
  `varnames`. A `TRUE` for an entry in `partial.match` and a `TRUE`
  for that same entry for `stringdist.match` means that a partial
  match category will be included in the gamma calculation.

Other arguments that can be provided include:

- `priors.obj`: The output from `calcMoversPriors()`, allowing the inclusion of auxiliary information on moving behavior to aid matching. We will discuss this option further at the end of this vignette.

- `w.lambda`: The user-specified weighting of the MLE and prior estimate for the $\lambda$ parameter, a number between 0 and 1. We will discuss this option further at the end of this vignette.

- `w.pi`: The user-specified weighting of the MLE and prior estimate for the $\pi$ parameter, a number between 0 and 1. We will discuss this option further at the end of this vignette.

- `l.address`: The number of possible matching categories used for address fields, used to calculate optimal hyperparameters for the $\pi$ prior. We will discuss this option further at the end of this vignette.

- `address.field`: A boolean vector the same length as `varnames`, where TRUE indicates an address matching field. Default is NULL. Should be specified in conjunction with `priors_obj`. We will discuss this option further at the end of this vignette.

- `n.cores`: The number of registered cores to parallelize over. If left unspecified. the function will
estimate this on its own.

- `tol.em`: Convergence tolerance for the EM algorithm. Default is 1e-04

- `match`: Lower bound for the posterior probability of a match that
will be accepted. Default is 0.85.

- `verbose`: Whether to print out runtime for each step and EM
output. Default is FALSE.

The output from `fastLink()` will be a list of length 2 with two
entries:

- `matches`: A matrix where each row is a match with the relevant
indices of `dfA` (column 1) and `dfB` (column 2).

- `EM`: The output from the EM algorithm.

- `nobs.a`: The number of observations in dataset A.

- `nobs.b`: The number of observations in dataset B.

The datasets can then be subsetted down to the matches as follows:
```{r}
dfA.match <- dfA[matches.out$matches$inds.a,]
dfB.match <- dfB[matches.out$matches$inds.b,]
```

We can also examine the EM object:
```{r}
matches.out$EM
```
where the first seven columns are indicators for the matching pattern for that field. `0` indicates no match on that field, `1` indicates a partial match, `2` indicates a complete match, and `NA` indicates an NA. Other columns are: 

- `counts`: Tallies the number of pairwise comparisons between `dfA` and `dfB` that fall in each pattern

- `weights`: The Fellegi-Sunter weight for each matching pattern

- `p.gamma.j.m`: Probability of being in the matched set given that matching pattern

- `p.gamma.j.u`: Probability of being in the unmatched set given that matching pattern

- `zeta.j`: Posterior probability of a particular pattern representing a true match

### Preprocessing Matches via Clustering
In order to reduce the number of pairwise comparisons that need to be conducted, researchers will often cluster similar observations from dataset A and dataset B together so that comparisons are only made between these maximally similar groups. Here, we implement a form of this clustering that uses word embedding, a common preprocessing method for textual data, to form maximally similar groups.

First, we provide some guidance on how to choose the variables to cluster on. We recommend specifically that researchers cluster on first name only - matching on address fields will fail to group people who move into the same group, while matching on last name will fail to cluster women who changed their last name after marriage. Date fields will often change due to administrative errors, and while there may be administrative errors in first name, the word embedding can accomodate those errors while clustering similar spellings in the same group.

The clustering proceeds in three steps. First, a word embedding matrix is created out of the provided data. For instance, a word embedding of the name `ben` would be a vector of length 26, where each entry in the vector represents a different letter. That matrix takes the value 0 for most entries, except for entry 2 (B), 5 (E), and 14 (N), which take the count of 1 (representing the number of times that letter appears in the string). Second, principal components analysis is run on the word embedding matrix. Last, a subset of dimensions from the PCA step are selected according to the amount of variance explained by the dimensions, and then the K-means algorithm is run on that subset of dimensions in order to form the clusters.

The `clusterWordEmbed()` function runs the clustering procedure from start to finish:
```{r}
cluster.out <- clusterWordEmbed(vecA = dfA$firstname, vecB = dfB$firstname, nclusters = 3)
```

- `vecA`: The variable to cluster on in dataset A.

- `vecB`: The variable to cluster on in dataset B.

- `nclusters`: The number of clusters to create. 

Other arguments that can be provided include:

- `max.n`: The maximum size of a dataset in a cluster. `nclusters` is then chosen to reflect this maximum n size. If `nclusters` is filled, then `max.n` should be left as NULL, and vice versa.

- `min.var`: The amount of variance the least informative dimension of the PCA should contribute in order to be included in the K-means step. The default value is .2 (out of 1).

- `weighted.kmeans`: Whether to weight the dimensions of the PCA used in the K-means algorithm by the amount of variance explained by each feature. Default is `TRUE`.

- `iter.max`: The maximum number of iterations the K-means algorithm should attempt to run. The default value is 5000.

The output of `clusterWordEmbed()` includes the following entries:

- `clusterA`: Cluster assignments for dataset A.

- `clusterB`: Cluster assignments for dataset B.

- `n.clusters`: The number of clusters created.

- `kmeans`: The output from the K-means algorithm.

- `pca`: The output from the PCA step.

- `dims.pca`: The number of dimensions from the PCA step included in the K-means algorithm.

### Running the algorithm step-by-step
The algorithm can also be run step-by-step for more flexibility. We outline how to do this in the following section, which replicates the example in the wrapper above.

#### 1) Agreement calculation variable-by-variable
The first step for running the `fastLink` algorithm is to determine
which observations agree, partially agree, disagree, and are missing
on which variables. All functions provide the indices of the NA's. There are three separate
`gammapar` functions to calculate this agreement variable-by-variable:

- `gammaKpar()`: Binary agree-disagree on non-string variables.

- `gammaCKpar()`: Agree-partial agree-disagree on string variables (using Jaro-Winkler distance to measure agreement).

- `gammaCK2par()`: Binary agree-disagree on string variables (using
Jaro-Winkler distance to measure agreement).

For instance, if we wanted to include partial string matches on `firstname`, `lastname`, and `streetname`, but only do exact string matches on `city` and `middlename` (with exact non-string matches on `birthyear` and `housenum`), we would run:
```{r}
g_firstname <- gammaCKpar(dfA$firstname, dfB$firstname)
g_middlename <- gammaCK2par(dfA$middlename, dfB$middlename)
g_lastname <- gammaCKpar(dfA$lastname, dfB$lastname)
g_housenum <- gammaKpar(dfA$housenum, dfB$housenum)
g_streetname <- gammaCKpar(dfA$streetname, dfB$streetname)
g_city <- gammaCK2par(dfA$city, dfB$city)
g_birthyear <- gammaKpar(dfA$birthyear, dfB$birthyear)
```
All functions include an `n.cores` argument where you can prespecify
the number of registered cores to be used. If you do not specify
this, the function will automatically detect the number of available
cores and wil parallelize over those. In addition, for `gammaCKpar()`
and `gammaCK2par()`, the user can specify the lower bound for an
agreement using `cut.a`. For both functions, the default is 0.92. For
`gammaCKpar()`, the user can also specify the lower bound for a
partial agreement using `cut.p` - here, the default is 0.88.

#### 2) Counting unique agreement patterns
Once we have run the gamma calculations, we then use the
`tableCounts()` function to count the number of unique matching
patterns in our data. This is the only input necessary for the EM
algorithm. We run `tableCounts()` as follows:
```{r}
gammalist <- list(g_firstname, g_middlename, g_lastname, g_housenum, g_streetname, g_city, g_birthyear)
tc <- tableCounts(gammalist, nobs.a = nrow(dfA), nobs.b = nrow(dfB))
```
As with the functions above, `tableCounts()` also includes an `n.cores`
argument. If left unspecified, the function will automatically
determine the number of available cores for parallelization.

#### 3) Running the EM algorithm
We next run the EM algorithm to calculate the Fellegi-Sunter
weights. The only required input to this function is the output from
`tableCounts()`, as follows:
```{r}
## Run EM algorithm
em.out <- emlinkMARmov(tc, nobs.a = nrow(dfA), nobs.b = nrow(dfB))

## Postprocessing of EM algorithm
EM <- data.frame(em.out$patterns.w)
EM$zeta.j <- em.out$zeta.j
EM <- EM[order(EM[, "weights"]), ] 
match.ut <- EM$weights[ EM$zeta.j >= 0.85 ][1]
```

As with the other functions above, `emlinkMARmov()` accepts an `n.cores`
argument. Other optional arguments include:

- `p.m`: Starting values for the probability of being in the matched
set

- `p.gamma.k.m`: Starting values for the probability that conditional
on being in the matched set, we observed a specific agreement value
for field k. A vector with length equal to the number of linkage
fields

- `p.gamma.k.u`: Starting values for the probability that conditional
on being in the unmatched set, we observed a specific agreement value
for field k. A vector with length equal to the number of linkage
fields

- `tol`: Convergence tolerance for the EM algorithm

- `iter.max`: Maximum number of iterations for the EM algorithm

and additional arguments that allow the user to specify priors calculated from auxiliary information. We will discuss these further at the end of this vignette.

The code following `emlinkMARmov()` sorts the linkage patterns by the
Fellegi-Sunter weight, and then selects the lowest weight that is
still classified as a positive match according to the posterior
probability that a linkage pattern is in the matched set. In this
case, we've chosen that probability to be 0.85.

#### 4) Finding the matches
Once we've run the EM algorithm and selected our lower bound for
accepting a match, we then run `matchesLink()` to get the paired
indices of `dfA` and `dfB` that match. We run the function as follows:
```{r}
matches.out <- matchesLink(gammalist, nobs.a = nrow(dfA), nobs.b = nrow(dfB),
                           em = em.out, cut = match.ut)
```
As with the other functions above, `matchesLink()` accepts an `n.cores`
argument. This returns a matrix where each row is a match with the relevant indices of
`dfA` (column 1) and `dfB` (column 2).

The datasets can then be subsetted down to the matches as follows:
```{r}
dfA.match <- dfA[matches.out[,1],]
dfB.match <- dfB[matches.out[,2],]
```

## Using Auxiliary Information to Inform `fastLink`
The `fastLink` algorithm also includes several ways to incorporate auxiliary
information on migration behavior to inform the matching of data sets over time. Auxiliary information is incorporated into the estimation as priors on two parameters of the model:

- $$\lambda$$: The probability that a randomly selected pair of observations from dataset A and dataset B are a true match. When matching, for example, the same state to itself in subsequent years, the prior for this quantity is equal to the number of non-movers to the number of in-state movers, divided by the size of the cross-product of A and B. When matching two different states in subsequent years to find movers, the numerator is the size of the outflow from state A to state B, divided by the size of the cross-product of A and B.

- $$\pi_{k,l}$$: The probability that an address field does not match conditional on being in the matched set. Specified when trying to find movers within the same geography over time. For example, when trying to find movers within the same state over time, this quantity is equal to the estimated number of in-state movers divided by the number of in-state movers and non-movers.

The functions `calcMoversPriors()` can be used to calculate estimates for the corresponding prior distributions using the IRS Statistics of Income Migration Data. 

Below, we show an example where we incorporate the auxiliary moving information for California into our estimates. First, we use `calcMoversPriors()` to estimate optimal parameter values for the priors:
```{r}
priors.out <- calcMoversPriors(geo.a = "CA", geo.b = "CA", year.start = 2014, year.end = 2015)
names(priors.out)
```
where the `lambda.prior` entry is the estimate of the match rate, while `pi.prior` is the estimate of the in-state movers rate. 

The `calcMoversPriors()` function accepts the following functions:

- `geo.a`: The state name or county name of dataset A

- `geo.b`: The state name or county name of dataset B

- `year.start`: The year of dataset A

- `year.end`: The year of dataset B

- `county`: Boolean, whether the geographies in `geo.a` or `geo.b` refer to counties or states. Default is FALSE

- `state.a`: If `county = TRUE`, the name of the state for `geo.a`

- `state.b`: If `county = TRUE`, the name of the state for `geo.b`

- `matchrate.lambda`: If TRUE, then returns the match rate for lambda (the expected share of observations in dataset A that can be found in dataset B). If FALSE, then returns the expected share of matches across all pairwise comparisons of datasets A and B. Default is FALSE.

- `remove.instate`: If TRUE, then for calculating cross-state movers rates assumes that successful matches have been subsetted out. The interpretation of the prior is then the match rate conditional on being an out-of-state or county mover. Default is TRUE.

### Incorporating Auxiliary Information with `fastLink()` Wrapper
We can re-run the full match above while incorporating auxiliary information as follows:
```{r}
priors.out <- list(lambda.prior = 50/(nrow(dfA) * nrow(dfB)), pi.prior = 0.02)
matches.out.aux <- fastLink(
  dfA = dfA, dfB = dfB, 
  varnames = c("firstname", "middlename", "lastname", "housenum", "streetname", "city", "birthyear"),
  stringdist.match = c(TRUE, TRUE, TRUE, FALSE, TRUE, TRUE, FALSE),
  partial.match = c(TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE),
  priors.obj = priors.out, 
  w.lambda = .5, w.pi = .5, l.address = 3, 
  address.field = c(FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE)
)
```
where `priors.obj` is an input for the the optimal prior parameters. This can be calculated by `calcMoversPriors()`, or can be provided by the user as a list with two entries named `lambda.prior` and `pi.prior`. `w.lambda` and `w.pi` are user-specified weights between 0 and 1 indicating the weighting between the MLE estimate and the prior, where a weight of 0 indicates no weight being placed on the prior. `address_field` is a vector of booleans of the same length as `varnames`, where `TRUE` indicates an address-related field used for matching. `l.address` is an integer indicating the number of matching fields used on the address variable - when a single partial match category is included, `l.address = 3`, while for a binary match/no match category `l.address = 2`.

### Incorporating Auxiliary Information when Running the Algorithm Step-by-Step
If we are running the algorithm step-by-step, we can incorporate the prior information into the EM algorithm as follows:
```{r}
em.out.aux <- emlinkMARmov(tc, nobs.a = nrow(dfA), nobs.b = nrow(dfB),
                           prior.lambda = priors.out$lambda.prior, w.lambda = .5,
                           prior.pi = priors.out$pi.prior, w.pi = .5,
                           address.field = c(FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE),
                           l.address = 3)
```
All other steps are the same. The newly specified arguments include the prior estimates of the parameters (`prior.lambda`, `prior.pi`), the weightings of the prior and MLE estimate (`w.lambda`, `w.pi`), the vector of boolean indicators where `TRUE` indicates an address field (`address.field`), and an integer indicating the number of matching categories for the address field (`l.address`).